{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69973a96",
   "metadata": {},
   "source": [
    "# 1. Data collection\n",
    "Sound of cars and trams are partly recorded and used during the trainingm and parts of them are from the Internet.\n",
    "\n",
    "For the recorded sounds:\n",
    "- source: trams and cars passing in Hervanta\n",
    "- what: the sound of trams arriving to the platform and cars passing\n",
    "- where: around Hervanta, particularly Opiskelija tram platform\n",
    "- method: a smartphone with audio recording software were used\n",
    "\n",
    "For the online sourced sounds:\n",
    "1. Tram\n",
    "- source: [tram](https://freesound.org/people/ilknur_bas/packs/37103/)\n",
    "- what: the sound of trams arriving to the platform and cars passing\n",
    "- where: around Tampere, Kaleva\n",
    "- method: an iPhone12 audio recording software were used\n",
    "2. Car\n",
    "- source: [car](https://freesound.org/people/trung1309vn/packs/39612/)\n",
    "- what: the sound of cars A passing by from distance\n",
    "- where: Hervannan valtaväylä road, Tampere\n",
    "- method: a Redmi 9C audio recording software were used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5727d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lb\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "data, sr = lb.load('data/tram/tram1.wav', sr=None)\n",
    "sd.play(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7667304",
   "metadata": {},
   "source": [
    "# 2. Feature extraction\n",
    "Online-downloaded audio are in .wav format\n",
    "\n",
    "For self-recorded sounds, the method used for .wav conversion were:\n",
    "- the recorded sounds were in the format .m4a\n",
    "- using librosa with ffmpeg package from [chocolatey](https://community.chocolatey.org/packages/ffmpeg) to read the .m4a file\n",
    "- use the output data and sample rate to write to a new .wav file using [soundfile](https://pypi.org/project/soundfile/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad4f9293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 9, 10]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "x = 3\n",
    "a[-x:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2720c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 240000)\n",
      "(27, 240000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "length_expected = int(48000 * 5)\n",
    "data_folder = 'data/'\n",
    "tram = []\n",
    "car = []\n",
    "for o in ['car', 'tram']:\n",
    "    data_files = data_folder + o + '/'\n",
    "    for name in os.listdir(data_files):\n",
    "        path = os.path.join(data_files, name)\n",
    "        if path.__contains__('.wav'):\n",
    "            data, sr = lb.load(path, sr=None)\n",
    "            # data cleansing\n",
    "            mean = np.mean(data)\n",
    "            std_dev = np.std(data)\n",
    "            normalized_data = (data - mean) / std_dev\n",
    "\n",
    "            length_data = len(normalized_data)\n",
    "            if length_data > length_expected:\n",
    "                remain = int(length_data - length_expected)\n",
    "                if normalized_data[:remain].sum() > normalized_data[-remain:].sum():\n",
    "                    normalized_data = normalized_data[:length_expected].copy()\n",
    "                else:\n",
    "                    normalized_data = normalized_data[-length_expected:].copy()\n",
    "\n",
    "            elif length_data < length_expected:\n",
    "                remain = int(length_expected - length_data)\n",
    "                added_noise = np.random.normal(loc=0.0, scale=1.0, size=(remain,))\n",
    "                normalized_data = np.concat([added_noise, normalized_data]).copy()\n",
    "            if path.__contains__('tram'):\n",
    "                tram.append(normalized_data)\n",
    "            else:\n",
    "                car.append(normalized_data)\n",
    "\n",
    "tram = np.array(tram)\n",
    "car = np.array(car)\n",
    "\n",
    "print(tram.shape)\n",
    "print(car.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
